{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归介绍\n",
    "- 线性回归是机器学习算法当中最基础的一个算法，是一个线性模型（不能挖掘数据之间的非线性关系）。\n",
    "- 输入是多个变量，输出一个实数值，范围是整个实数空间即[-∞, +∞]\n",
    "- 一般用于解决回归问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数学表达式\n",
    "假设数据输入是一个向量$x=[x_1, x_2, x_3, x_4, x_5,...., x_n]$，输出是一个实数值$y$，其数学表达式如下所示:\n",
    "$$\n",
    "y = xw^T+b\n",
    "$$\n",
    "- $x$是1行n列的矩阵，即数据的输入$x$\n",
    "- $w$是线性回归模型的参数，是一个1行n列的矩阵，$T$表示矩阵的转置\n",
    "- $b$是一个实数，表示线性回归的偏置项"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归的优点\n",
    "- 建模速度快，因为不需要很复杂的计算（不需要进行指数运算什么之类的）\n",
    "- 模型自带解释，从参数$w$可以看除哪个变量对最终结果的影响最大\n",
    "\n",
    "## 线性回归的缺点\n",
    "- 不能挖掘数据的非线性关系,对于非线性相关的数据来说模型过于简单以至于不能得到很好的结果\n",
    "- 需要假设数据不存在非线性的关系，建模之前需要严格的假设\n",
    "- 对变量的异常值非常敏感"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一个小demo\n",
    "给出一个函数，然后给数据的输出加上一个噪音，构成一个数据训练集\n",
    "\n",
    "假设目标的函数是：\n",
    "$$\n",
    "y = 3x_1+5.6x_2+9.4x_3+10.4x_5+0.444\n",
    "$$\n",
    "## 训练过程\n",
    "我们的目标就是得到$x_1$、$x_2$、$x_3$、$x_4$、$x_5$、$b$(0.444就是b)这几个参数\n",
    "\n",
    "1. 随机初始化上述几个参数的数值\n",
    "2. 损失函数使用mse\n",
    "3. 使用梯度下降算法来进行参数的更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.   5.6  9.4 10.4] 0.444\n",
      "[1.8529184 1.9021056 1.9214013 2.003685 ] 0.24211327731609344\n",
      "------------------------\n",
      "[ 3.   5.6  9.4 10.4] 0.444\n",
      "[5.492904 6.655674 8.159406 9.20212 ] 0.24187128245830536\n",
      "------------------------\n",
      "[ 3.   5.6  9.4 10.4] 0.444\n",
      "[4.2492027 5.9966645 8.410351  9.463966 ] 0.24162951111793518\n",
      "------------------------\n",
      "[ 3.   5.6  9.4 10.4] 0.444\n",
      "[3.6671007 5.818971  8.9215355 9.995118 ] 0.2413879930973053\n",
      "------------------------\n",
      "[ 3.   5.6  9.4 10.4] 0.444\n",
      "[ 3.3860586  5.7363944  9.129061  10.168412 ] 0.24114671349525452\n",
      "------------------------\n",
      "[ 3.   5.6  9.4 10.4] 0.444\n",
      "[ 3.206347  5.687012  9.257879 10.298907] 0.24090568721294403\n",
      "------------------------\n",
      "[ 3.   5.6  9.4 10.4] 0.444\n",
      "[ 3.105652   5.6471004  9.344035  10.355228 ] 0.24066488444805145\n",
      "------------------------\n",
      "[ 3.   5.6  9.4 10.4] 0.444\n",
      "[ 3.041664   5.6167226  9.3728285 10.375135 ] 0.24042432010173798\n",
      "------------------------\n",
      "[ 3.   5.6  9.4 10.4] 0.444\n",
      "[ 3.0177956  5.604609   9.376344  10.3784   ] 0.240184023976326\n",
      "------------------------\n",
      "[ 3.   5.6  9.4 10.4] 0.444\n",
      "[ 3.0274584  5.620292   9.405159  10.405093 ] 0.23994393646717072\n",
      "------------------------\n",
      "[ 3.   5.6  9.4 10.4] 0.444\n",
      "[ 3.0148573  5.6089587  9.402211  10.403028 ] 0.23970410227775574\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "import  torch\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# 目标参数\n",
    "target_param = torch.tensor([3, 5.6, 9.4, 10.4])\n",
    "target_param = target_param.view(4, 1)\n",
    "target_bias = 0.444\n",
    "\n",
    "def target_f(x):\n",
    "    '''\n",
    "    x是一个向量，即 5 个特征的值\n",
    "    return number\n",
    "    '''\n",
    "    return x.mm(target_param) + target_bias\n",
    "\n",
    "\n",
    "def get_batch_data(batch_size=32):\n",
    "    # 让x的范围大一点\n",
    "    x = torch.rand(batch_size,4)*random.randint(0, 100)\n",
    "    y = target_f(x)\n",
    "    return x, y+random.random()*2\n",
    "\n",
    "# 初始化线性模型参数\n",
    "train_param = torch.ones(4, 1, requires_grad=True)\n",
    "train_bias = torch.rand(1, requires_grad=True)\n",
    "\n",
    "batch_size = 66\n",
    "epoch = 100\n",
    "lr = 0.0001\n",
    "# 训练1000次\n",
    "for i in range(0, epoch+1):\n",
    "    x, y = get_batch_data(batch_size)\n",
    "    out = x.mm(train_param)+train_bias\n",
    "    loss = F.mse_loss(y, out)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        train_param -= lr*train_param.grad\n",
    "        train_bias -= lr*train_bias\n",
    "        train_param.grad.zero_()\n",
    "        train_bias.grad.zero_()\n",
    "    if i % 10 == 0:\n",
    "        print(target_param.detach().numpy().reshape(-1), target_bias)\n",
    "        print(train_param.detach().numpy().reshape(-1), train_bias.item())\n",
    "        print('-'*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
