{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "个人经常在选择损失函数的时候犯迷糊，所以这篇文章是记录一下pytorch常见损失函数的数学表达式及其实现的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 构造数据，假设batch_size=5，标签是10个类别\n",
    "y_hat = torch.zeros(5, 10)\n",
    "y = torch.ones(5, 10)\n",
    "y_i = torch.tensor([1, 2, 3, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1Loss损失函数\n",
    "计算MAE，即差值的绝对值，就是一个L1范数所以也叫做L1Loss，假设$\\hat{y}$是预测值，$y$是真实的标签值，那么这个损失值就用如下的数学表达式表示：\n",
    "$$\n",
    "loss\\_value = |\\hat{y} - y|\n",
    "$$\n",
    "在pytorch中，该损失函数是一个类，需要初始化后才能使用，有三个初始化参数：\n",
    "- ~~size_average~~, \n",
    "- ~~reduce,~~ \n",
    "- reduction，'sum' or 'mean'，'sum'表示对所有损失值进行求和，'mean'表示求当前batch总体的损失值。默认是取值'mean'\n",
    "三个参数其实描述的是同一个东西，但前两个参数是过时的（[见文档](https://pytorch.org/docs/stable/nn.html#l1loss)），所以我们只需要使用**reduction**参数就好了,**后续的损失函数都是如此设计的，就不会再陈述了**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(50.)\n"
     ]
    }
   ],
   "source": [
    "L1_mean = nn.L1Loss(reduction='mean')\n",
    "loss_mean = L1_mean(y_hat, y)\n",
    "print(loss_mean)\n",
    "\n",
    "L1_sum = nn.L1Loss(reduction='sum')\n",
    "loss_sum = L1_sum(y_hat, y)\n",
    "print(loss_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSELoss损失函数\n",
    "计算均方误差，数学表达式如下：\n",
    "$$\n",
    "loss\\_value = (y - \\hat{y})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(50.)\n"
     ]
    }
   ],
   "source": [
    "mse_mean = nn.MSELoss(reduction='mean')\n",
    "mse_sum = nn.MSELoss(reduction='sum')\n",
    "loss_mean = mse_mean(y, y_hat)\n",
    "loss_sum = mse_sum(y, y_hat)\n",
    "print(loss_mean)\n",
    "print(loss_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossEntropyLoss\n",
    "交叉熵函数，**适用于多分类问题**，数学表达式如下：\n",
    "$$\n",
    "loss\\_value(x, class) = -log(\\frac{e^{x[class]}}{\\sum_{j}{e^{x[j]}}}) = -x[class] + log(\\sum_{j} x[j])\n",
    "$$\n",
    "其中，x是一个1D tensor，class是下标（或者标签）。\n",
    "\n",
    "对于类的初始化，除了考虑**reduction**这个参数，还有如下几个参数：\n",
    "- weight, 一个与类别数量长度相同的tensor，用了这个参数的话，我们的损失函数就变为了：$loss\\_value(x, class) = weight[class](-x[class] + log(\\sum_{j} x[j]))$\n",
    "- ignore_index ,范围是[0, C-1]之间的整数，C表示类别的数量。这个参数是一个整数表明某个类别不需要参与损失函数的计算，相当于少了某一个类。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.5129)\n",
      "tensor(2.3026)\n",
      "weight...\n",
      "tensor(2.7631)\n",
      "tensor(2.3026)\n",
      "ignore index...\n",
      "tensor(6.9078)\n",
      "tensor(2.3026)\n"
     ]
    }
   ],
   "source": [
    "cel_sum = nn.CrossEntropyLoss(reduction='sum')\n",
    "cel_mean = nn.CrossEntropyLoss(reduction='mean')\n",
    "# 第一个参数是形如(N, C)的tensor，第二个参数是（N，）的tensor，每个值是第一个参数C的某个下标\n",
    "loss_sum = cel_sum(y_hat, y_i)\n",
    "loss_mean = cel_mean(y_hat, y_i)\n",
    "print(loss_sum)\n",
    "print(loss_mean)\n",
    "\n",
    "print('weight...')\n",
    "weight = torch.tensor([0.1, 0.2, 0.3, 0.2, 0.2, 0, 0, 0, 0, 0])\n",
    "cel_sum_w = nn.CrossEntropyLoss(weight=weight, reduction='sum')\n",
    "cel_mean_w = nn.CrossEntropyLoss(weight=weight, reduction='mean')\n",
    "# 第一个参数是形如(N, C)的tensor，第二个参数是（N，）的tensor，每个值是第一个参数C的某个下标\n",
    "loss_sum = cel_sum_w(y_hat, y_i)\n",
    "loss_mean = cel_mean_w(y_hat, y_i)\n",
    "print(loss_sum)\n",
    "print(loss_mean)\n",
    "\n",
    "print('ignore index...')\n",
    "cel_sum = nn.CrossEntropyLoss(ignore_index=1,reduction='sum')\n",
    "cel_mean = nn.CrossEntropyLoss(ignore_index=1, reduction='mean')\n",
    "# 第一个参数是形如(N, C)的tensor，第二个参数是（N，）的tensor，每个值是第一个参数C的某个下标\n",
    "loss_sum = cel_sum(y_hat, y_i)\n",
    "loss_mean = cel_mean(y_hat, y_i)\n",
    "print(loss_sum)\n",
    "print(loss_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
